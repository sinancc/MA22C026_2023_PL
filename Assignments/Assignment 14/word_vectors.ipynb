{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4IwFeO-bZsJU"
      },
      "outputs": [],
      "source": [
        "c = { \\\n",
        "'Lincoln1865':\n",
        "'With malice toward none, with charity for all ...' +\n",
        "'let us strive on to finish the work we are in ... ' +\n",
        "'to do all which may achieve and cherish a just and lasting peace, ' +\n",
        "'among ourselves, and with all nations.',\n",
        "\n",
        "'TrumpMay26':\n",
        "'There is NO WAY (ZERO!) that Mail-In Ballots ' +\n",
        "'will be anything less than substantially fraudulent.',\n",
        "\n",
        "'Wikipedia':\n",
        "'In 1998, Oregon became the first state in the US ' +\n",
        "'to conduct all voting exclusively by mail.',\n",
        "\n",
        "'FortuneMay26':\n",
        "'Over the last two decades, about 0.00006% of total ' +\n",
        "'vote-by-mail votes cast were fraudulent.',\n",
        "\n",
        "'TheHillApr07':\n",
        "'Trump voted by mail in the Florida primary.',\n",
        "\n",
        "'KingJamesBible':\n",
        "'Wherefore laying aside all malice, and all guile, and ' +\n",
        "'hypocrisies, and envies, and all evil speakings',\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import spacy"
      ],
      "metadata": {
        "id": "cMMGFwAfaTHX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a CountVectorizer object\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the text data\n",
        "X = vectorizer.fit_transform(c.values())\n",
        "\n",
        "# Create a DataFrame from the term-document matrix\n",
        "term_document_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out(), index=c.keys())\n",
        "\n",
        "# Display the DataFrame\n",
        "print(term_document_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQE1JM6gunPk",
        "outputId": "4596f4b7-5f1a-4ef8-a577-5e8d0fb8e5b8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                00006  1998  about  achieve  all  among  and  anything  are  \\\n",
            "Lincoln1865         0     0      0        1    3      1    3         0    1   \n",
            "TrumpMay26          0     0      0        0    0      0    0         1    0   \n",
            "Wikipedia           0     1      0        0    1      0    0         0    0   \n",
            "FortuneMay26        1     0      1        0    0      0    0         0    0   \n",
            "TheHillApr07        0     0      0        0    0      0    0         0    0   \n",
            "KingJamesBible      0     0      0        0    3      0    4         0    0   \n",
            "\n",
            "                aside  ...  voting  way  we  were  wherefore  which  will  \\\n",
            "Lincoln1865         0  ...       0    0   1     0          0      1     0   \n",
            "TrumpMay26          0  ...       0    1   0     0          0      0     1   \n",
            "Wikipedia           0  ...       1    0   0     0          0      0     0   \n",
            "FortuneMay26        0  ...       0    0   0     1          0      0     0   \n",
            "TheHillApr07        0  ...       0    0   0     0          0      0     0   \n",
            "KingJamesBible      1  ...       0    0   0     0          1      0     0   \n",
            "\n",
            "                with  work  zero  \n",
            "Lincoln1865        3     1     0  \n",
            "TrumpMay26         0     0     1  \n",
            "Wikipedia          0     0     0  \n",
            "FortuneMay26       0     0     0  \n",
            "TheHillApr07       0     0     0  \n",
            "KingJamesBible     0     0     0  \n",
            "\n",
            "[6 rows x 78 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load a compatible spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define a custom tokenizer function using spaCy's lemmatization\n",
        "def spacy_tokenizer(text):\n",
        "    tokens = nlp(text)\n",
        "    lemmas = [token.lemma_ for token in tokens if not token.is_punct and not token.is_space]\n",
        "    return lemmas\n",
        "# Create a CountVectorizer instance with the custom tokenizer\n",
        "vectorizer = CountVectorizer(tokenizer=spacy_tokenizer)\n",
        "\n",
        "# Fit and transform the corpus using CountVectorizer\n",
        "X = vectorizer.fit_transform(c.values())\n",
        "\n",
        "# Convert the result to a data frame with clear labeling\n",
        "term_document_matrix = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out(), index=c.keys())\n",
        "\n",
        "# Display the term-document matrix\n",
        "print(term_document_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he214M4WurfK",
        "outputId": "2ac39fbc-fcc7-457a-fa34-5edb5dbe0961"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                0.00006  1998  a  about  achieve  all  among  and  anything  \\\n",
            "Lincoln1865           0     0  1      0        1    3      1    3         0   \n",
            "TrumpMay26            0     0  0      0        0    0      0    0         1   \n",
            "Wikipedia             0     1  0      0        0    1      0    0         0   \n",
            "FortuneMay26          1     0  0      1        0    0      0    0         0   \n",
            "TheHillApr07          0     0  0      0        0    0      0    0         0   \n",
            "KingJamesBible        0     0  0      0        0    3      0    4         0   \n",
            "\n",
            "                aside  ...  vote  voting  way  we  wherefore  which  will  \\\n",
            "Lincoln1865         0  ...     0       0    0   2          0      1     0   \n",
            "TrumpMay26          0  ...     0       0    1   0          0      0     1   \n",
            "Wikipedia           0  ...     0       1    0   0          0      0     0   \n",
            "FortuneMay26        0  ...     2       0    0   0          0      0     0   \n",
            "TheHillApr07        0  ...     1       0    0   0          0      0     0   \n",
            "KingJamesBible      1  ...     0       0    0   0          1      0     0   \n",
            "\n",
            "                with  work  zero  \n",
            "Lincoln1865        3     1     0  \n",
            "TrumpMay26         0     0     1  \n",
            "Wikipedia          0     0     0  \n",
            "FortuneMay26       0     0     0  \n",
            "TheHillApr07       0     0     0  \n",
            "KingJamesBible     0     0     0  \n",
            "\n",
            "[6 rows x 74 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Create an LSA (Latent Semantic Analysis) model\n",
        "lsa = TruncatedSVD(n_components=3)\n",
        "\n",
        "# Fit the LSA model to the term-document matrix\n",
        "lsa_result = lsa.fit_transform(X)\n",
        "\n",
        "# Create a DataFrame for the LSA representations\n",
        "lsa_df = pd.DataFrame(lsa_result, index=c.keys(), columns=[\"LSA1\", \"LSA2\", \"LSA3\"])\n",
        "\n",
        "# Print the LSA representation of all documents\n",
        "print(\"LSA representations of documents:\")\n",
        "print(lsa_df)\n",
        "\n",
        "# Find the vector representation of the word \"vote\"\n",
        "word_index = vectorizer.vocabulary_.get(\"vote\")\n",
        "if word_index is not None:\n",
        "    word_vector = lsa.components_[:, word_index]\n",
        "    print(\"Vector representation of 'vote':\", word_vector)\n",
        "else:\n",
        "    print(\"The word 'vote' is not in the vocabulary.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V-s_i0ZvHOd",
        "outputId": "b3056f49-b291-4843-f06c-38b44318d217"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSA representations of documents:\n",
            "                    LSA1      LSA2      LSA3\n",
            "Lincoln1865     7.386029  0.089226 -2.288112\n",
            "TrumpMay26      0.520975  2.218354  0.487372\n",
            "Wikipedia       1.578395  2.968300  0.739028\n",
            "FortuneMay26    0.445616  2.771292  1.199554\n",
            "TheHillApr07    0.412929  1.751775  0.544510\n",
            "KingJamesBible  4.116111 -2.054894  3.576262\n",
            "Vector representation of 'vote': [0.01747558 0.25405951 0.14328202]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Define a function to compute cosine similarity\n",
        "def compute_cosine_similarity(vector1, vector2):\n",
        "    # Reshape the vectors to be 2D arrays (required for cosine_similarity)\n",
        "    vector1 = vector1.reshape(1, -1)\n",
        "    vector2 = vector2.reshape(1, -1)\n",
        "\n",
        "    # Compute the cosine similarity\n",
        "    similarity = cosine_similarity(vector1, vector2)\n",
        "\n",
        "    return similarity[0][0]\n",
        "v1=lsa_df.loc['Lincoln1865'].to_numpy()\n",
        "v2= lsa_df.loc['Wikipedia'].to_numpy()\n",
        "v3= lsa_df.loc['TrumpMay26'].to_numpy()\n",
        "# Compute cosine similarity between 'malice' and 'vote'\n",
        "cosine_malice_vote = compute_cosine_similarity(v1,v2)\n",
        "\n",
        "# Compute cosine similarity between 'mail' and 'vote'\n",
        "cosine_mail_vote = compute_cosine_similarity(v3,v2)\n",
        "\n",
        "print(f\"Cosine similarity between 'malice' and 'vote': {cosine_malice_vote}\")\n",
        "print(f\"Cosine similarity between 'mail' and 'vote': {cosine_mail_vote}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH7ewf_Nvhz9",
        "outputId": "105a32d4-906f-4251-d6ac-f9842e9e84eb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'malice' and 'vote': 0.3844065678276618\n",
            "Cosine similarity between 'mail' and 'vote': 0.9683590759737166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "# Create a TfidfVectorizer object\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the text data to compute the TF-IDF matrix\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(c.values())\n",
        "\n",
        "# Create a DataFrame from the TF-IDF matrix\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out(), index=c.keys())\n",
        "\n",
        "# Display the TF-IDF matrix\n",
        "print(tfidf_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9AF0soWv4-Y",
        "outputId": "ae5312cd-d91e-4ca5-a59c-bc6f7be91a82"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  00006      1998    about   achieve       all     among  \\\n",
            "Lincoln1865     0.00000  0.000000  0.00000  0.147276  0.305882  0.147276   \n",
            "TrumpMay26      0.00000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
            "Wikipedia       0.00000  0.272458  0.00000  0.000000  0.188626  0.000000   \n",
            "FortuneMay26    0.26865  0.000000  0.26865  0.000000  0.000000  0.000000   \n",
            "TheHillApr07    0.00000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
            "KingJamesBible  0.00000  0.000000  0.00000  0.000000  0.426225  0.000000   \n",
            "\n",
            "                     and  anything       are     aside  ...    voting  \\\n",
            "Lincoln1865     0.362304   0.00000  0.147276  0.000000  ...  0.000000   \n",
            "TrumpMay26      0.000000   0.26374  0.000000  0.000000  ...  0.000000   \n",
            "Wikipedia       0.000000   0.00000  0.000000  0.000000  ...  0.272458   \n",
            "FortuneMay26    0.000000   0.00000  0.000000  0.000000  ...  0.000000   \n",
            "TheHillApr07    0.000000   0.00000  0.000000  0.000000  ...  0.000000   \n",
            "KingJamesBible  0.673126   0.00000  0.000000  0.205218  ...  0.000000   \n",
            "\n",
            "                    way        we     were  wherefore     which     will  \\\n",
            "Lincoln1865     0.00000  0.147276  0.00000   0.000000  0.147276  0.00000   \n",
            "TrumpMay26      0.26374  0.000000  0.00000   0.000000  0.000000  0.26374   \n",
            "Wikipedia       0.00000  0.000000  0.00000   0.000000  0.000000  0.00000   \n",
            "FortuneMay26    0.00000  0.000000  0.26865   0.000000  0.000000  0.00000   \n",
            "TheHillApr07    0.00000  0.000000  0.00000   0.000000  0.000000  0.00000   \n",
            "KingJamesBible  0.00000  0.000000  0.00000   0.205218  0.000000  0.00000   \n",
            "\n",
            "                    with      work     zero  \n",
            "Lincoln1865     0.441827  0.147276  0.00000  \n",
            "TrumpMay26      0.000000  0.000000  0.26374  \n",
            "Wikipedia       0.000000  0.000000  0.00000  \n",
            "FortuneMay26    0.000000  0.000000  0.00000  \n",
            "TheHillApr07    0.000000  0.000000  0.00000  \n",
            "KingJamesBible  0.000000  0.000000  0.00000  \n",
            "\n",
            "[6 rows x 78 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create a TfidfVectorizer object\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the text data to compute the TF-IDF matrix\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(c.values())\n",
        "\n",
        "# Create a DataFrame from the TF-IDF matrix\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out(), index=c.keys())\n",
        "\n",
        "# Define the word vectors for \"malice,\" \"vote,\" and \"mail\"\n",
        "malice_vector = tfidf_df.loc['Lincoln1865'].values.reshape(1, -1)\n",
        "vote_vector = tfidf_df.loc['Wikipedia'].values.reshape(1, -1)\n",
        "mail_vector = tfidf_df.loc['TrumpMay26'].values.reshape(1, -1)\n",
        "\n",
        "# Compute the cosine similarity between word vectors\n",
        "cosine_malice_vote = cosine_similarity(malice_vector, vote_vector)\n",
        "cosine_mail_vote = cosine_similarity(mail_vector, vote_vector)\n",
        "\n",
        "# Print the results\n",
        "print(\"Cosine similarity between 'malice' and 'vote' using TF-IDF:\", cosine_malice_vote[0, 0])\n",
        "print(\"Cosine similarity between 'mail' and 'vote' using TF-IDF:\", cosine_mail_vote[0, 0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX8_pu6bwXT7",
        "outputId": "1b6c50f5-71fe-4af1-b501-1ef08c19de84"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'malice' and 'vote' using TF-IDF: 0.19513415920023014\n",
            "Cosine similarity between 'mail' and 'vote' using TF-IDF: 0.0758726657016838\n"
          ]
        }
      ]
    }
  ]
}